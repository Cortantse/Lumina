# Lumina é¡¹ç›®

## é¡¹ç›®ç®€ä»‹

Lumina æ˜¯ä¸€ä¸ªå¤šæ¨¡å‹èåˆçš„å®æ—¶å¯¹è¯ç³»ç»Ÿï¼ŒåŒ…å«è¯­éŸ³è¯†åˆ«ï¼ˆSTTï¼‰ã€è¯­ä¹‰è½®æ¬¡æ£€æµ‹ï¼ˆSTDï¼‰ã€å¤šæ¨¡æ€è¾“å…¥å¤„ç†ï¼ˆæ–‡æœ¬ã€è¯­éŸ³ã€å›¾åƒï¼‰ã€é•¿çŸ­æœŸè®°å¿†ç®¡ç†ã€ä»¥åŠå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆTTSï¼‰æœåŠ¡ã€‚

é¡¹ç›®æµç¨‹å›¾ï¼š
![archi](https://github.com/user-attachments/assets/7655ce84-c09b-44ad-ac36-3510b101026e)


---

## é¡¹ç›®ç»“æ„

```
lumina/
â”œâ”€â”€ frontend/                         # å‰ç«¯æ¡Œé¢å®¢æˆ·ç«¯ï¼ˆTauri + Vue3ï¼‰
â”‚   â”œâ”€â”€ src/                          # é¡µé¢é€»è¾‘ä¸ç»„ä»¶
â”‚   â”œâ”€â”€ public/                       # é™æ€èµ„æº
â”‚   â”œâ”€â”€ tauri.conf.json               # Tauri é…ç½®
â”‚   â””â”€â”€ package.json                  # å‰ç«¯ä¾èµ–ä¸è„šæœ¬
â”‚
â”œâ”€â”€ backend/                          # FastAPI åç«¯æ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ api/                          # å¯¹å¤– HTTP/WebSocket æ¥å£
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ chat.py               # /chat æµå¼æ¥å£
â”‚   â”‚       â”œâ”€â”€ multimodal.py         # /image, /event ç­‰æ¥å£
â”‚   â”‚       â””â”€â”€ control.py            # æ§åˆ¶æ¶ˆæ¯ï¼šend_of_segment, cancel
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                         # å…¨å±€é…ç½®ã€åˆå§‹åŒ–ã€ç›‘æ§
â”‚   â”‚   â”œâ”€â”€ config.py                 # è¯»å– envã€å‚æ•°
â”‚   â”‚   â”œâ”€â”€ logging.py                # ç»“æ„åŒ–æ—¥å¿—
â”‚   â”‚   â””â”€â”€ metrics.py                # åŸ‹ç‚¹ & æ—¶å»¶ç»Ÿè®¡
â”‚   â”‚
â”‚   â”œâ”€â”€ protocols/                    # å„ç§æ¨¡å—é—´è¡Œä¸ºæ¥å£å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ stt.py                    # class STTClient(Protocol)
â”‚   â”‚   â”œâ”€â”€ vad.py                    # å‰ç«¯å·²å®ç°ï¼Œæœ¬é¡¹ç›®ç•™ç©ºï¼Œä»…ç”¨äºç±»å‹æ£€æŸ¥
â”‚   â”‚   â”œâ”€â”€ std.py                    # class TurnDetector(Protocol)
â”‚   â”‚   â”œâ”€â”€ llm.py                    # class LLMClient(Protocol)
â”‚   â”‚   â”œâ”€â”€ tts.py                    # class TTSClient(Protocol)
â”‚   â”‚   â””â”€â”€ memory.py                 # class MemoryStore(Protocol)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                       # æ•°æ®ç±» (DTO/domain)
â”‚   â”‚   â”œâ”€â”€ audio.py                  # @dataclass AudioFrame, SpeechSegment
â”‚   â”‚   â”œâ”€â”€ transcript.py             # @dataclass PartialTranscript, FinalTranscript
â”‚   â”‚   â””â”€â”€ dialogue.py               # @dataclass DialogueContext, MemoryItem
â”‚   â”‚                   
â”‚   â”œâ”€â”€ stt/                          # æµå¼è¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ iflytek_client.py         # ç§‘å¤§è®¯é£ STT å°è£…å®ç°
â”‚   â”‚   â””â”€â”€ websocket_adapter.py      # WebSocket æ¥æ”¶å¸§/å‘é€å¸§é€‚é…
â”‚   â”‚
â”‚   â”œâ”€â”€ std/                          # è¯­ä¹‰è½®æ¬¡æ£€æµ‹
â”‚   â”‚   â”œâ”€â”€ rule_based.py             # è§„åˆ™å¯å‘å¼æ£€æµ‹
â”‚   â”‚   â””â”€â”€ llm_based.py              # åŸºäºLLMè¯­ä¹‰æ£€æµ‹
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                          # LLM æ¥å…¥å±‚
â”‚   â”‚   â”œâ”€â”€ openai_client.py          # OpenAI æ¥å…¥å°è£…
â”‚   â”‚   â””â”€â”€ local_llm.py              # æœ¬åœ° LLM å°è£…
â”‚   â”‚
â”‚   â”œâ”€â”€ tts/                          # æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆå¾…ç¡®å®šä¾›åº”å•†ï¼‰                         
â”‚   â”‚   â”œâ”€â”€ ???.py                    # å¾…å®š
â”‚   â”‚
â”‚   â”œâ”€â”€ multimodal/                   # å¤šæ¨¡æ€æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ audio_model.py            # éŸ³é¢‘å¤§æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ vision_model.py           # è§†è§‰æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ ocr.py                    # OCR æœåŠ¡
â”‚   â”‚   â””â”€â”€ handler.py                # å¤šæ¨¡æ€æ¶ˆæ¯è½¬å‘å¤„ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                       # é•¿çŸ­æœŸè®°å¿†å­˜å‚¨
â”‚   â”‚   â”œâ”€â”€ store.py                  # FAISS å‘é‡å­˜å‚¨å®ç°
â”‚   â”‚   â””â”€â”€ embeddings.py             # æ–‡æœ¬å‘é‡åŒ–å°è£…
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/                    # è®°å¿†æ£€ç´¢
â”‚   â”‚   â””â”€â”€ retriever.py              # ä½™å¼¦ç›¸ä¼¼åº¦æ£€ç´¢å®ç°
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                     # æ ¸å¿ƒç¼–æ’æµæ°´çº¿
â”‚   â”‚   â”œâ”€â”€ orchestrator.py           # å¯¹è¯ç¼–æ’ Orchestrator
â”‚   â”‚   â”œâ”€â”€ context_manager.py        # DialogueContext ç”Ÿå‘½å‘¨æœŸç®¡ç†
â”‚   â”‚   â””â”€â”€ pipeline.py               # STTâ†’STDâ†’Memoryâ†’LLMâ†’TTS æµæ°´çº¿
â”‚   â”‚
â”‚   â””â”€â”€ main.py                       # FastAPI + WebSocket å¯åŠ¨å…¥å£
â”‚
â”œâ”€â”€ tests/                            # æµ‹è¯•
â”‚   â”œâ”€â”€ unit/                         # å•å…ƒæµ‹è¯•
â”‚   â””â”€â”€ integration/                  # é›†æˆæµ‹è¯•
â”‚
â”œâ”€â”€ docker/                           # Docker å®¹å™¨åŒ–éƒ¨ç½²
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ requirements.txt                  # Python ä¾èµ–åŒ…
â””â”€â”€ README.md                         # æœ¬æ–‡æ¡£
```

---

## æ¥å£è§„èŒƒè¯´æ˜

æ‰€æœ‰æ¨¡å—ä½¿ç”¨ä»¥ä¸‹ Python è§„èŒƒç¡®ä¿æ¨¡å—è§£è€¦æ¸…æ™°ï¼š

### Protocolï¼ˆæ¥å£åè®®ï¼‰

Protocol ç”¨äºå®šä¹‰æ¨¡å—è¡Œä¸ºæ¥å£ï¼Œæ— éœ€ç»§æ‰¿ç‰¹å®šåŸºç±»ï¼Œåªéœ€æ˜ç¡®æ–¹æ³•ç­¾åå³å¯ã€‚ç¤ºä¾‹ï¼š

```python
from typing import Protocol

class STTClient(Protocol):
    async def send_audio(self, segment: SpeechSegment) -> PartialTranscript: ...
    async def close_stream(self) -> FinalTranscript: ...
```

### Dataclassï¼ˆæ•°æ®ç±»ï¼‰

Dataclass æ˜¯ç”¨äºç»“æ„åŒ–æ•°æ®ä¼ è¾“çš„æ•°æ®ç±»ï¼Œè‡ªåŠ¨å®ç°äº†åˆå§‹åŒ–å’Œè¡¨ç¤ºæ–¹æ³•ã€‚

```python
from dataclasses import dataclass

@dataclass
class AudioFrame:
    data: bytes
    timestamp: float
```



---

# Lumina

Lumina is a real-time multimodal dialogue system that integrates streaming STT, semantic turn detection, memory retrieval, and multi-agent LLM orchestration. æœ¬é¡¹ç›®ä¸º Lumina çš„å‰åç«¯ä¸€ä½“åŒ–ä»“åº“ï¼Œé€‚ç”¨äºæ¡Œé¢çº§å¯¹è¯åŠ©æ‰‹åŸå‹æ„å»ºã€‚

é¡¹ç›®æ ¸å¿ƒæµç¨‹å›¾è¯·å‚è€ƒï¼š[Archi æ¶æ„å›¾](./archi.png)

---

## ğŸ“ é¡¹ç›®ç»“æ„æ€»è§ˆ

```
lumina/
â”œâ”€â”€ backend/                         # FastAPI åç«¯æ ¸å¿ƒé€»è¾‘
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api/                    # HTTP/WebSocket æ¥å£
â”‚       â”œâ”€â”€ core/                   # é…ç½®ã€æ—¥å¿—ã€ç›‘æ§
â”‚       â”œâ”€â”€ protocols/              # å„æ¨¡å—åè®®æ¥å£å®šä¹‰
â”‚       â”œâ”€â”€ models/                 # æ•°æ®ç±»å®šä¹‰
â”‚       â”œâ”€â”€ stt/                    # æµå¼è¯­éŸ³è¯†åˆ«å®¢æˆ·ç«¯ï¼ˆå¦‚è®¯é£ï¼‰
â”‚       â”œâ”€â”€ std/                    # è¯­ä¹‰è½®æ¬¡æ£€æµ‹æ¨¡å—
â”‚       â”œâ”€â”€ llm/                    # LLM æ¥å…¥ï¼ˆOpenAI / æœ¬åœ°ï¼‰
â”‚       â”œâ”€â”€ tts/                    # TTS æ¥å…¥æ¨¡å—ï¼ˆå¾…å®šï¼‰
â”‚       â”œâ”€â”€ multimodal/             # å¤šæ¨¡æ€è¾“å…¥å¤„ç†ï¼ˆå›¾åƒã€éŸ³é¢‘ï¼‰
â”‚       â”œâ”€â”€ memory/                 # è®°å¿†å­˜å‚¨ï¼ˆFAISS ç­‰ï¼‰
â”‚       â”œâ”€â”€ retrieval/              # æ£€ç´¢å¼•æ“ï¼ˆå‘é‡ç›¸ä¼¼åº¦ï¼‰
â”‚       â”œâ”€â”€ services/               # ç¼–æ’æµç¨‹ Orchestrator
â”‚       â””â”€â”€ main.py                 # å¯åŠ¨å…¥å£
â”‚
â”œâ”€â”€ frontend/                        # å‰ç«¯æ¡Œé¢å®¢æˆ·ç«¯ï¼ˆTauri + Vue3ï¼‰
â”‚   â”œâ”€â”€ src/                        # é¡µé¢é€»è¾‘ä¸ç»„ä»¶
â”‚   â”œâ”€â”€ public/                     # é™æ€èµ„æº
â”‚   â”œâ”€â”€ tauri.conf.json             # Tauri é…ç½®
â”‚   â””â”€â”€ package.json                # å‰ç«¯ä¾èµ–ä¸è„šæœ¬
â”‚
â”œâ”€â”€ docker/                          # Docker & å®¹å™¨éƒ¨ç½²
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ tests/                           # å•å…ƒ + é›†æˆæµ‹è¯•
â”œâ”€â”€ archi.png                        # æ¶æ„æµç¨‹å›¾
â”œâ”€â”€ requirements.txt                # åç«¯ä¾èµ–
â””â”€â”€ README.md                       # å½“å‰è¯´æ˜æ–‡æ¡£
```

---

## ğŸ”— æ¨¡å—æ¥å£åè®®ï¼ˆProtocolï¼‰

é‡‡ç”¨ Python 3 çš„ `typing.Protocol` å®šä¹‰æ¨¡å—ä¹‹é—´çš„æ¥å£åè®®ï¼Œä¿æŒä½è€¦åˆã€å¼ºè§„èŒƒï¼š

```python
# protocols/stt.py
from typing import Protocol
class STTClient(Protocol):
    async def send_audio(self, segment: SpeechSegment) -> PartialTranscript: ...
    async def close_stream(self) -> FinalTranscript: ...
```

* âœ… **æ‰€æœ‰æ¨¡å—é€šè¿‡åè®®æ³¨å…¥ï¼Œä¾¿äº Mock ä¸æ›¿æ¢å®ç°**
* âœ… LLMClientã€TurnDetectorã€TTSClient ç­‰çš†é‡‡ç”¨æ­¤è§„èŒƒ

---

## ğŸ“¦ æ•°æ®æ¨¡å‹ï¼ˆ@dataclassï¼‰

æ•°æ®æ¨¡å‹ç”¨äºæ¨¡å—é—´ä¼ é€’ä¸­é—´çŠ¶æ€ï¼Œä½¿ç”¨ `@dataclass` å®šä¹‰ç»“æ„åŒ–å¯¹è±¡ï¼š

```python
@dataclass
class AudioFrame:
    data: bytes
    timestamp: float

@dataclass
class DialogueContext:
    user_id: str
    history: List[str]
    current_utterance: Optional[str] = None
```

---

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### å®‰è£…åç«¯ä¾èµ–

```bash
cd backend
pip install -r requirements.txt
```

### å¯åŠ¨åç«¯æœåŠ¡

```bash
cd backend
python app/main.py
```

### å®‰è£…å‰ç«¯ä¾èµ–

```bash
cd frontend
npm install
```

### å¯åŠ¨å‰ç«¯ï¼ˆTauri + Vue3ï¼‰

```bash
npm run tauri dev
```

### Docker ä¸€é”®å¯åŠ¨

```bash
docker-compose up --build
```

---

## âœ… æ³¨æ„äº‹é¡¹

* âœ… å‰ç«¯å·²å®ç°éº¦å…‹é£é‡‡é›†ä¸ VADï¼Œæœ¬é¡¹ç›®åç«¯ä»…å¤„ç†å·²è£å‰ªçš„äººå£°æ®µè½ã€‚
* âœ… æ§åˆ¶æµï¼ˆå¦‚ `end_of_segment`, `cancel`ï¼‰é€šè¿‡ WebSocket å•ç‹¬é€šé“ä¼ è¾“ã€‚
* âœ… è‹¥æ—  final transcript è¶…æ—¶ï¼Œå‰ç«¯éœ€ä¸»åŠ¨è§¦å‘ end-of-streamã€‚

---

## ğŸ§ª æµ‹è¯•æ‰§è¡Œ

```bash
pytest tests/
```

---

## ğŸ§  è®¾è®¡ç›®æ ‡

* æä½æ—¶å»¶ï¼ˆéŸ³é¢‘æ®µè½ç»“æŸå <500ms è§¦å‘å›åº”ï¼‰
* å¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾åƒã€è¯­éŸ³ã€äº‹ä»¶ï¼‰ç»Ÿä¸€å¤„ç†è·¯å¾„
* é¢å‘ Agent åœºæ™¯çš„è®°å¿†å­˜å–ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥å¯¹è¯
* LLM å¯é…ç½®ï¼ˆæ”¯æŒ OpenAI / æœ¬åœ°æ¨¡å‹ / æ’ä»¶ï¼‰

---

æ¬¢è¿è´¡çŒ®è€…åŠ å…¥ä¸€èµ·å®Œå–„ Luminaï¼


